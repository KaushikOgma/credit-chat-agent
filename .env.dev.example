
# SERVER CONFIGURATION
PROJECT_NAME="American Credit Genius"
PROJECT_VERSION="0.1"
APP_PORT="8000"
PROJECT_ROOT_PATH="/"
PROJECT_ENV="dev"
LOCAL_UPLOAD_LOCATION="./uploads"
LOG_FILE="./app.log"
MODULE="credit-genius-ai"
MAX_THREADS='10'
MAX_PROCESSES='3'
ACCEPTED_DATE_TIME_STRING="%Y-%m-%d %H:%M:%S"
# APP_TIMEZONE="America/Los_Angeles"
# APP_TIMEZONE="UTC"
APP_TIMEZONE="Asia/Kolkata"


# Model configuration
OPENAI_API_KEY=
PROMPT_FILE='app/utils/prompts.yaml'
AVERAGE_QUESTION_TOKEN_SIZE='40'
AVERAGE_ANSWER_TOKEN_SIZE='200'
AVERAGE_QUESTION_TEXT_RATIO='0.17' # 0.17 is the average question text ratio -> AVERAGE_QUESTION_TOKEN_SIZE / ( AVERAGE_QUESTION_TOKEN_SIZE + AVERAGE_ANSWER_TOKEN_SIZE)
BASE_MODEL_FOR_FINETUNE="gpt-4o-2024-08-06"
BASE_AUDIO_MODEL="whisper-1"

# config for 'gpt-4o-mini' model
BASE_MODEL='gpt-4o-mini'
ADVANCE_MODEL='gpt-4o'
BASE_MODEL_TOKEN_LIMIT='4096' # Same as GPT-3.5-turbo for context length
BASE_MODEL_TOKENS_PER_MESSAGE='3'

# # config for 'gpt-4o' model
# MODEL='gpt-4o'
# MODEL_TOKEN_LIMIT='128000' # GPT-4o supports up to 128k context length
# MODEL_TOKENS_PER_MESSAGE='3'

# # config for 'gpt-3.5-turbo' model
# TURBO_MODEL='gpt-3.5-turbo'
# TURBO_MODEL_TOKEN_LIMIT='4096' # GPT-3.5-turbo supports up to 4096 context length
# TURBO_MODEL_T

# DB Configuration
PINECONE_API_KEY=
EMBEDDING_MODEL_NAME="text-embedding-ada-002"
VECTOR_DB_NAME="qa-pairs"
VECTOR_DIMENSION="1536"

DB_NAME=
DB_PROTOCOL=
DB_HOST=
DB_PORT=
DB_USER=
DB_PASSWORD=
SEEDING="1"
VERBOSE="1"


# Array Configuration
ARRAY_APP_KEY=
ARRAY_SERVER_TOKEN=
ARRAY_BASE_URL=https://sandbox.array.io/api
# ARRAY_BASE_URL=https://array.io/api

CHAT_HISTORY_LIMIT="10"
CHAT_HISTORY_DISPLAY_LIMIT="10"
FREE_CHAT_LIMIT="10"
SERVER_URL="https://ai.credit-genius.com"
TEST_USER_ID=
TEST_ARRAY_USER_ID=